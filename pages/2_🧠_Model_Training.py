# pages/2_ğŸ§ _Model_Training.py - VERSION RÃ‰FÃ‰RENTE AVEC ModelTrainer

import streamlit as st
import pandas as pd
import numpy as np
import sys
from pathlib import Path
import time
from sklearn.metrics import r2_score
from sklearn.preprocessing import RobustScaler
from sklearn.multioutput import MultiOutputRegressor
import gc
import warnings

warnings.filterwarnings('ignore')

# IMPORTS DL
try:
    import tensorflow as tf
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    st.warning("âš ï¸ TensorFlow non disponible â†’ `pip install tensorflow`")

# Styles + header
from styles import inject_global_styles, page_header
inject_global_styles()
page_header("ğŸ§  EntraÃ®nement ModÃ¨les", "Ã‰tape 2/6 - Benchmark 14 ModÃ¨les 5G")

# PATHS & utils
BASE_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(BASE_DIR / 'utils'))
sys.path.insert(0, str(BASE_DIR))

from utils.model_trainer import ModelTrainer

# VÃ‰RIFICATIONS
required_keys = ["processed_data", "features", "targets", "raw_metrics"]
missing = [k for k in required_keys if k not in st.session_state or st.session_state[k] is None]

if missing:
    st.error(f"âŒ **Page 1 incomplÃ¨te** : {', '.join(missing)} manquantes")
    st.info("ğŸ’¡ Retournez Ã  la page 1 pour prÃ©parer le dataset.")
    st.stop()

df_norm = st.session_state.processed_data
raw_df = st.session_state.raw_metrics
features = st.session_state.features
targets = st.session_state.targets

st.info(f"ğŸ“Š **Dataset prÃ©parÃ©** : {len(df_norm):,} intervalles | **{len(features)} features** â†’ **{len(targets)} cibles**")
st.info(f"ğŸ¯ **Cibles sÃ©lectionnÃ©es** : {targets}")

# =========================
# CONFIGURATION UTILISATEUR
# =========================
st.subheader("âš™ï¸ **Configuration de l'EntraÃ®nement**")

col1, col2, col3 = st.columns(3)
sequence_length = col1.slider(
    "Longueur sÃ©quence (lookback)",
    30, 120, 60,
    help="Nombre de pas de temps historiques utilisÃ©s pour prÃ©dire"
)
prediction_horizon = col2.slider(
    "Horizon prÃ©diction (steps ahead)",
    1, 30, 10,
    help="Nombre de pas de temps futurs Ã  prÃ©dire"
)
test_size = col3.slider("Taille jeu test (%)", 10, 40, 20) / 100

col1, col2 = st.columns(2)
epochs = col1.number_input(
    "Epochs Deep Learning", 10, 200, 30,
    help="Nombre d'itÃ©rations d'entraÃ®nement pour les rÃ©seaux neuronaux"
)
batch_size = col2.selectbox(
    "Batch Size DL", [16, 32, 64, 128], index=1,
    help="Taille des lots pour l'entraÃ®nement DL"
)

# =========================
# SÃ‰LECTION DES MODÃˆLES
# =========================
st.subheader("ğŸ¤– **SÃ©lection des ModÃ¨les Ã  EntraÃ®ner**")

models_to_train = [
    "Persistence (baseline)",
    "Moving Average (baseline)",
    "Linear Regression",
    "Random Forest",
    "XGBoost",
    "Gradient Boosting",
    "LSTM",
    "GRU",
    "BiLSTM",
    "CNN_LSTM",
    "Transformer",
    "MLP",
    "Ensemble Voting",
    "Ensemble Stacking"
]

selected_models = st.multiselect(
    "Choisissez les modÃ¨les Ã  comparer :",
    models_to_train,
    default=["XGBoost", "Random Forest", "LSTM", "Gradient Boosting", "Linear Regression"],
    help="SÃ©lectionnez au moins 2 modÃ¨les pour une comparaison significative"
)

if len(selected_models) < 2:
    st.warning("âš ï¸ SÃ©lectionnez au moins 2 modÃ¨les pour comparer leurs performances")
    st.stop()

# =========================
# BOUTON D'ENTRAÃNEMENT
# =========================
if st.button("ğŸš€ **Lancer l'EntraÃ®nement des ModÃ¨les**", type="primary", use_container_width=True):
    with st.spinner(f"ğŸ”„ EntraÃ®nement de {len(selected_models)} modÃ¨les en cours..."):
        try:
            # VÃ©rification colonnes
            all_cols = features + targets
            missing_cols = [col for col in all_cols if col not in df_norm.columns]
            if missing_cols:
                st.error(f"âŒ Colonnes manquantes dans le dataset : {missing_cols}")
                st.stop()

            # =========================
            # SÃ©quences via ModelTrainer
            # =========================
            trainer = ModelTrainer(
                data=df_norm,
                sequence_length=sequence_length,
                prediction_horizon=prediction_horizon,
                test_size=test_size
            )

            st.info("ğŸ“ˆ CrÃ©ation des sÃ©quences temporelles...")
            X_train, X_test, y_train, y_test = trainer.prepare_sequences(features, targets, max_sequences=10000)

            if X_train.size == 0:
                st.error("âŒ Pas assez de donnÃ©es pour crÃ©er des sÃ©quences")
                st.info(f"ğŸ’¡ RÃ©duisez sequence_length ({sequence_length}) ou prediction_horizon ({prediction_horizon})")
                st.stop()

            st.success(
                f"âœ… {X_train.shape[0] + X_test.shape[0]} sÃ©quences crÃ©Ã©es : "
                f"Train={X_train.shape[0]}, Test={X_test.shape[0]} | "
                f"X.shape={X_train.shape}, y.shape={y_train.shape}"
            )

            # =========================
            # SCALER sur les targets
            # =========================
            n_targets = len(targets)
            target_scaler = RobustScaler()

            y_train_flat = y_train.reshape(-1, n_targets)
            y_test_flat = y_test.reshape(-1, n_targets)

            y_train_scaled_flat = target_scaler.fit_transform(y_train_flat)
            y_test_scaled_flat = target_scaler.transform(y_test_flat)

            y_train = y_train_scaled_flat.reshape(y_train.shape)
            y_test = y_test_scaled_flat.reshape(y_test.shape)

            st.session_state.target_scaler = target_scaler
            st.success("âœ… Scaling des targets terminÃ©")

            # =========================
            # ENTRAÃNEMENT DES MODÃˆLES
            # =========================
            results = []
            trained_models = {}
            y_preds_cache = {}  # Pour ensembles

            for model_name in selected_models:
                start_time = time.time()
                st.info(f"ğŸ”„ EntraÃ®nement : {model_name}...")

                try:
                    # Cas ensembles: on les traitera aprÃ¨s
                    if model_name in ["Ensemble Voting", "Ensemble Stacking"]:
                        continue

                    # Utiliser ModelTrainer pour tous les autres
                    model, y_pred, metrics = trainer.train_and_evaluate(
                        model_name=model_name,
                        X_train=X_train,
                        y_train=y_train,
                        X_test=X_test,
                        y_test=y_test,
                        epochs=epochs,
                        batch_size=batch_size,
                        verbose=0
                    )

                    trained_models[model_name] = model
                    y_preds_cache[model_name] = y_pred

                    results.append({
                        'Model': metrics['Model'],
                        'MAE': round(metrics['MAE'], 4),
                        'R2': round(metrics['R2'], 3),
                        'Train_Time_s': round(metrics['Train_Time_s'], 2),
                        'Status': 'âœ…'
                    })

                    st.success(
                        f"âœ… {model_name} : MAE={metrics['MAE']:.4f}, "
                        f"RÂ²={metrics['R2']:.3f}, Time={metrics['Train_Time_s']:.1f}s"
                    )

                except Exception as e:
                    st.warning(f"âš ï¸ Erreur sur {model_name} : {str(e)[:100]}...")
                    results.append({
                        'Model': model_name,
                        'MAE': np.nan,
                        'R2': np.nan,
                        'Train_Time_s': np.nan,
                        'Status': 'âŒ'
                    })

                gc.collect()

            # =========================
            # ENSEMBLES (Voting / Stacking)
            # =========================
            from sklearn.linear_model import LinearRegression as MetaLinearRegression

            if "Ensemble Voting" in selected_models:
                ml_models = ['Linear Regression', 'Random Forest', 'XGBoost', 'Gradient Boosting']
                available = [m for m in ml_models if m in trained_models]
                if len(available) >= 2:
                    X_test_flat = X_test.reshape(X_test.shape[0], -1)
                    preds = []
                    for m_name in available:
                        model_obj = trained_models[m_name]
                        if hasattr(model_obj, 'predict'):
                            y_pred_flat = model_obj.predict(X_test_flat)
                            preds.append(y_pred_flat)
                    if preds:
                        pred_flat_avg = np.mean(preds, axis=0)
                        y_pred_ens = pred_flat_avg.reshape(-1, prediction_horizon, n_targets)

                        mae = float(np.mean(np.abs(y_test - y_pred_ens)))
                        r2 = float(r2_score(y_test.reshape(-1), y_pred_ens.reshape(-1)))
                        train_time = time.time() - start_time

                        trained_models["Ensemble Voting"] = available
                        results.append({
                            'Model': "Ensemble Voting",
                            'MAE': round(mae, 4),
                            'R2': round(r2, 3),
                            'Train_Time_s': round(train_time, 2),
                            'Status': 'âœ…'
                        })

            if "Ensemble Stacking" in selected_models:
                ml_models = ['Linear Regression', 'Random Forest', 'Gradient Boosting']
                available = [m for m in ml_models if m in trained_models]
                if len(available) >= 2:
                    X_train_flat = X_train.reshape(X_train.shape[0], -1)
                    X_test_flat = X_test.reshape(X_test.shape[0], -1)

                    train_base_preds = []
                    test_base_preds = []

                    for m_name in available:
                        model_obj = trained_models[m_name]
                        if hasattr(model_obj, 'predict'):
                            train_base_preds.append(model_obj.predict(X_train_flat))
                            test_base_preds.append(model_obj.predict(X_test_flat))

                    if train_base_preds and test_base_preds:
                        train_meta_X = np.concatenate(train_base_preds, axis=1)
                        test_meta_X = np.concatenate(test_base_preds, axis=1)

                        y_train_meta = y_train.reshape(y_train.shape[0], -1)
                        y_test_meta = y_test.reshape(y_test.shape[0], -1)

                        meta_model = MetaLinearRegression()
                        meta_model.fit(train_meta_X, y_train_meta)

                        pred_meta = meta_model.predict(test_meta_X)
                        y_pred_stack = pred_meta.reshape(y_test.shape)

                        mae = float(np.mean(np.abs(y_test - y_pred_stack)))
                        r2 = float(r2_score(y_test.reshape(-1), y_pred_stack.reshape(-1)))
                        train_time = time.time() - start_time

                        trained_models["Ensemble Stacking"] = {
                            'meta': meta_model,
                            'base': available
                        }

                        results.append({
                            'Model': "Ensemble Stacking",
                            'MAE': round(mae, 4),
                            'R2': round(r2, 3),
                            'Train_Time_s': round(train_time, 2),
                            'Status': 'âœ…'
                        })

            # =========================
            # SAUVEGARDE DES RÃ‰SULTATS
            # =========================
            results_df = pd.DataFrame(results)
            results_df = results_df.dropna().sort_values('MAE').reset_index(drop=True)
            results_df['Rank'] = results_df.index + 1

            st.session_state.model_results = results_df
            st.session_state.trained_models = trained_models
            st.session_state.X_test = X_test
            st.session_state.y_test = y_test
            st.session_state.sequence_length = sequence_length
            st.session_state.prediction_horizon = prediction_horizon
            st.session_state.models_trained = True

            # =========================
            # AFFICHAGE
            # =========================
            st.markdown("---")
            st.subheader("ğŸ† **Classement des ModÃ¨les**")

            display_cols = ['Rank', 'Model', 'MAE', 'R2', 'Train_Time_s', 'Status']
            st.dataframe(results_df[display_cols], use_container_width=True, height=400)

            if len(results_df) > 0:
                best_model = results_df.iloc[0]
                col1, col2, col3 = st.columns(3)
                col1.metric("ğŸ¥‡ **Meilleur modÃ¨le**", best_model['Model'])
                col2.metric("ğŸ“‰ **Meilleur MAE**", f"{best_model['MAE']:.4f}")
                col3.metric("â­ **Meilleur RÂ²**", f"{best_model['R2']:.3f}")
                st.success(f"âœ… EntraÃ®nement terminÃ© ! {len(results_df)} modÃ¨les comparÃ©s.")

            if st.button("ğŸ¤– **Page 3 : PrÃ©dictions & Visualisation**", type="primary"):
                st.switch_page("pages/3_ğŸ¤–_Real_Time_Predictions.py")

        except Exception as e:
            st.error(f"âŒ Erreur lors de l'entraÃ®nement : {str(e)}")
            import traceback
            st.code(traceback.format_exc())

# AFFICHAGE SI DÃ‰JÃ€ ENTRAÃNÃ‰
if st.session_state.get('models_trained', False):
    st.markdown("---")
    st.subheader("ğŸ“Š **RÃ©sultats d'EntraÃ®nement Existants**")

    results_df = st.session_state.model_results

    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ“ˆ ModÃ¨les entraÃ®nÃ©s", len(results_df))
    col2.metric("ğŸ¯ Cibles", len(targets))
    col3.metric("â±ï¸ Horizon", f"{st.session_state.get('prediction_horizon', 'N/A')}s")

    st.dataframe(
        results_df[['Model', 'MAE', 'R2', 'Train_Time_s']].head(10),
        use_container_width=True
    )

    if st.button("â¡ï¸ **Passer aux PrÃ©dictions**", type="primary"):
        st.switch_page("pages/3_ğŸ¤–_Real_Time_Predictions.py")
